{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNilX1J+hxE5GP1qyyJ2Tgm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Sil_bHr6Osf4","colab_type":"text"},"source":["**cross validation 한다**"]},{"cell_type":"code","metadata":{"id":"ooK6CXUkQ83K","colab_type":"code","outputId":"0084ab42-175a-42f0-a291-b3f645d173a4","executionInfo":{"status":"ok","timestamp":1590417446914,"user_tz":-540,"elapsed":20129,"user":{"displayName":"­김소현(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"14982175216887538737"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k2VwRz7DO3Gw","colab_type":"text"},"source":["**데이터 전처리는 동일**"]},{"cell_type":"code","metadata":{"id":"h_mUYG6pQ-xH","colab_type":"code","outputId":"c05af16a-f542-4c72-97cf-787f6ad9b247","executionInfo":{"status":"ok","timestamp":1590418160288,"user_tz":-540,"elapsed":3003,"user":{"displayName":"­김소현(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"14982175216887538737"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["import pandas as pd\n","import numpy as np\n","\n","data = pd.read_csv(\"/gdrive/My Drive/classification/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n","df_sample = data.loc[:, ['Init_Win_bytes_forward', ' Avg Fwd Segment Size',' Init_Win_bytes_backward', ' Fwd Header Length.1',' Label']]\n","df_labels= df_sample[' Label']\n","df_packets=df_sample.drop([' Label'],axis='columns')\n","\n","#같은 길이 나오는 거확인\n","print(len(df_sample))\n","print(len(df_labels))\n","print(len(df_packets))\n","\n","#콜롬 목록과 데이터 타입 확인 후 변환\n","df_packets.columns\n","#type(df_sample)\n","df_packets = df_packets.astype(float) #형변환\n","\n","#리스트로 되돌리기\n","packets= df_packets.values.tolist()\n","labels= df_labels.values.tolist()\n","\n","\n","#확인\n","packets[1]\n","labels[1]\n","\n","#길이 확인\n","len(packets)\n","len(labels)\n","#len(packets[1]) #한개당 80차원\n","\n","#기왕 하는거 labels도 float으로 바꿔주기\n","for c in range(225745):\n","  if (labels[c] == 'BENIGN' ):\n","    labels[c]=0 #false\n","  else:\n","    labels[c] =1 #true\n"," \n","\n","#테스트 군과 학습군으로 나누기.\n","#전체는 225745개. (70%는 약 158,021 개)\n","train_set = packets[:158021]\n","test_set = packets[158021:]\n","train_label =labels[:158021]\n","test_label = labels[158021:]\n","\n","train_set = np.asarray(train_set)\n","train_label = np.asarray(train_label)\n","test_set = np.asarray(test_set)\n","test_label = np.asarray(test_label)\n","\n","\n","#잘 나눠졌는지 확인\n","print(len(train_set) + len(test_set))\n","print(len(test_label) + len(train_label))\n","\n","train_set = np.expand_dims(train_set, axis=2) #reshape\n","test_set = np.expand_dims(test_set, axis=2) #reshape\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["225745\n","225745\n","225745\n","225745\n","225745\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nzwypQ_7RV4w","colab_type":"code","outputId":"76b6e90e-d3da-4a8d-cf56-d7544ede1dbb","executionInfo":{"status":"ok","timestamp":1590419371672,"user_tz":-540,"elapsed":1051082,"user":{"displayName":"­김소현(엘텍공과대학 소프트웨어학부)","photoUrl":"","userId":"14982175216887538737"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#cross validation\n","import tensorflow as tf\n","from sklearn.model_selection import KFold\n","num_folds = 10 #폴드 수 결정\n","\n","kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","\n","# acc와 lose를 저장해뒀다가 나중에 평균치 계산\n","acc_per_fold = []\n","loss_per_fold = []\n","\n","# Merge inputs and targets\n","inputs = np.concatenate((test_set, train_set), axis=0)\n","targets = np.concatenate((test_label, train_label), axis=0)\n","\n","\n","#모델\n","foldnum = 1\n","for train, test in kfold.split(inputs, targets):\n","  model = tf.keras.Sequential([\n","  tf.keras.layers.Conv1D(16, (2), activation='relu', input_shape=(4, 1)),\n","  tf.keras.layers.MaxPooling1D(2,padding='same'),\n","  tf.keras.layers.Conv1D(16, (2), activation='relu'),\n","  tf.keras.layers.MaxPooling1D(2, padding='same'),\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(512, activation='relu'),\n","  tf.keras.layers.Dense(256, activation='relu'),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dense(15, activation='softmax')\n","  ])\n","  #compile\n","  model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","  #결과\n","  history = model.fit(inputs[train], targets[train], epochs=5) #10번의 epoch\n","  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n","  print(f'Score for fold {foldnum}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n","  acc_per_fold.append(scores[1] * 100)\n","  loss_per_fold.append(scores[0])\n","  #다음 fold로\n","  foldnum = foldnum + 1\n","\n","\n","print('------------------------------------------------------------------------')\n","print('Score per fold')\n","for i in range(0, len(acc_per_fold)):\n","  print('------------------------------------------------------------------------')\n","  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n","print('------------------------------------------------------------------------')\n","print('Average scores for all folds:')\n","print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n","print(f'> Loss: {np.mean(loss_per_fold)}')\n","print('------------------------------------------------------------------------')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.5534 - accuracy: 0.9632\n","Epoch 2/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0663 - accuracy: 0.9851\n","Epoch 3/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0478 - accuracy: 0.9888\n","Epoch 4/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0581 - accuracy: 0.9875\n","Epoch 5/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0264 - accuracy: 0.9942\n","Score for fold 1: loss of 0.029964419081807137; accuracy of 99.43743348121643%\n","Epoch 1/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.5233 - accuracy: 0.9605\n","Epoch 2/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0688 - accuracy: 0.9844\n","Epoch 3/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.1281 - accuracy: 0.9581\n","Epoch 4/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.1617 - accuracy: 0.9460\n","Epoch 5/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.1153 - accuracy: 0.9665\n","Score for fold 2: loss of 0.07598689943552017; accuracy of 98.33000898361206%\n","Epoch 1/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.4587 - accuracy: 0.9617\n","Epoch 2/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0396 - accuracy: 0.9932\n","Epoch 3/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0284 - accuracy: 0.9940\n","Epoch 4/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0330 - accuracy: 0.9940\n","Epoch 5/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0331 - accuracy: 0.9923\n","Score for fold 3: loss of 0.01661340519785881; accuracy of 99.45957660675049%\n","Epoch 1/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.3895 - accuracy: 0.9735\n","Epoch 2/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0520 - accuracy: 0.9909\n","Epoch 3/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0395 - accuracy: 0.9928\n","Epoch 4/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0261 - accuracy: 0.9946\n","Epoch 5/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0224 - accuracy: 0.9955\n","Score for fold 4: loss of 0.013937425799667835; accuracy of 99.66777563095093%\n","Epoch 1/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.3188 - accuracy: 0.9641\n","Epoch 2/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0829 - accuracy: 0.9772\n","Epoch 3/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0811 - accuracy: 0.9802\n","Epoch 4/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0733 - accuracy: 0.9834\n","Epoch 5/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0965 - accuracy: 0.9791\n","Score for fold 5: loss of 0.13079491257667542; accuracy of 96.10188007354736%\n","Epoch 1/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.3579 - accuracy: 0.8604\n","Epoch 2/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.3510 - accuracy: 0.8425\n","Epoch 3/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.3227 - accuracy: 0.8441\n","Epoch 4/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.3427 - accuracy: 0.8491\n","Epoch 5/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.3528 - accuracy: 0.8494\n","Score for fold 6: loss of 0.33777564764022827; accuracy of 85.23079752922058%\n","Epoch 1/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.3222 - accuracy: 0.9669\n","Epoch 2/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.2325 - accuracy: 0.9105\n","Epoch 3/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.2488 - accuracy: 0.8847\n","Epoch 4/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0795 - accuracy: 0.9772\n","Epoch 5/5\n","6350/6350 [==============================] - 20s 3ms/step - loss: 0.0824 - accuracy: 0.9741\n","Score for fold 7: loss of 0.02858773246407509; accuracy of 99.17604327201843%\n","Epoch 1/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.2166 - accuracy: 0.9811\n","Epoch 2/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0458 - accuracy: 0.9915\n","Epoch 3/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0540 - accuracy: 0.9904\n","Epoch 4/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0280 - accuracy: 0.9941\n","Epoch 5/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0271 - accuracy: 0.9937\n","Score for fold 8: loss of 0.023302454501390457; accuracy of 99.64118003845215%\n","Epoch 1/5\n","6350/6350 [==============================] - 23s 4ms/step - loss: 0.5155 - accuracy: 0.9678\n","Epoch 2/5\n","6350/6350 [==============================] - 23s 4ms/step - loss: 0.0571 - accuracy: 0.9874\n","Epoch 3/5\n","6350/6350 [==============================] - 23s 4ms/step - loss: 0.0717 - accuracy: 0.9775\n","Epoch 4/5\n","6350/6350 [==============================] - 22s 4ms/step - loss: 0.2838 - accuracy: 0.8489\n","Epoch 5/5\n","6350/6350 [==============================] - 23s 4ms/step - loss: 0.2783 - accuracy: 0.8527\n","Score for fold 9: loss of 0.3242259621620178; accuracy of 83.42783451080322%\n","Epoch 1/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.4966 - accuracy: 0.9643\n","Epoch 2/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0354 - accuracy: 0.9933\n","Epoch 3/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0248 - accuracy: 0.9951\n","Epoch 4/5\n","6350/6350 [==============================] - 25s 4ms/step - loss: 0.0224 - accuracy: 0.9950\n","Epoch 5/5\n","6350/6350 [==============================] - 21s 3ms/step - loss: 0.0205 - accuracy: 0.9958\n","Score for fold 10: loss of 0.02694183774292469; accuracy of 99.34437870979309%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.029964419081807137 - Accuracy: 99.43743348121643%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.07598689943552017 - Accuracy: 98.33000898361206%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.01661340519785881 - Accuracy: 99.45957660675049%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.013937425799667835 - Accuracy: 99.66777563095093%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.13079491257667542 - Accuracy: 96.10188007354736%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.33777564764022827 - Accuracy: 85.23079752922058%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.02858773246407509 - Accuracy: 99.17604327201843%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.023302454501390457 - Accuracy: 99.64118003845215%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.3242259621620178 - Accuracy: 83.42783451080322%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.02694183774292469 - Accuracy: 99.34437870979309%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 95.98169088363647 (+- 5.926538157537707)\n","> Loss: 0.10081306966021657\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OkE5pTAZTh9q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}